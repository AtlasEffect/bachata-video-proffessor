{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bachata Dance Analysis Demo\n",
    "\n",
    "This notebook demonstrates the complete Bachata Video Professor pipeline for extracting dance combinations from YouTube videos.\n",
    "\n",
    "## Overview\n",
    "\n",
    "The pipeline performs the following steps:\n",
    "1. **Video Loading**: Downloads or loads video from YouTube/local file\n",
    "2. **Pose Detection**: Uses MediaPipe to detect human poses on CPU\n",
    "3. **Multi-person Tracking**: Tracks all people and selects primary dancing couple\n",
    "4. **Feature Extraction**: Extracts motion features for each frame\n",
    "5. **Segmentation**: Identifies individual dance combinations\n",
    "6. **Role Identification**: Determines leader/follower roles\n",
    "7. **Output Generation**: Creates JSON, text summary, and annotated video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's install the required packages and import the necessary modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (uncomment if running in Colab/Kaggle)\n",
    "# !pip install mediapipe opencv-python numpy scipy tqdm pydantic yt-dlp matplotlib scikit-learn\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the src directory to Python path\n",
    "if os.path.exists('../src'):\n",
    "    sys.path.append('../src')\n",
    "elif os.path.exists('./src'):\n",
    "    sys.path.append('./src')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import Video, HTML\n",
    "\n",
    "from bachata_analyzer import BachataAnalyzer, AnalysisConfig\n",
    "from bachata_analyzer.models import AnalysisResult, DanceSegment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Let's set up the analysis configuration. You can adjust these parameters based on your needs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure analysis parameters\n",
    "config = AnalysisConfig(\n",
    "    fps=12,                    # Frames per second for analysis\n",
    "    max_width=1280,            # Maximum video width (downscale for speed)\n",
    "    min_segment_sec=4.0,       # Minimum segment length in seconds\n",
    "    pose_confidence=0.5,       # MediaPipe pose confidence threshold\n",
    "    tracking_confidence=0.5,   # MediaPipe tracking confidence threshold\n",
    "    create_video=True,         # Create annotated video output\n",
    "    use_temporal_smoothing=True,  # Apply temporal smoothing to keypoints\n",
    "    smoothing_window=5,        # Window size for temporal smoothing\n",
    "    change_point_sensitivity=0.8,  # Sensitivity for detecting combo changes\n",
    "    pause_threshold=0.3        # Threshold for detecting pauses\n",
    ")\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(f\"  FPS: {config.fps}\")\n",
    "print(f\"  Max Width: {config.max_width}px\")\n",
    "print(f\"  Min Segment Length: {config.min_segment_sec}s\")\n",
    "print(f\"  Create Video: {config.create_video}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Videos\n",
    "\n",
    "Here are the test videos we'll analyze:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example YouTube URLs\n",
    "example_videos = {\n",
    "    \"bachata_demo_1\": \"https://youtu.be/4V7EccGsSUI?si=m-hxgRejZcg-b1nD\",\n",
    "    \"bachata_demo_2\": \"https://youtu.be/OIEpCz8Q97A?si=k08QOEL5rkqALeDH\",\n",
    "    \"bachata_demo_3\": \"https://youtu.be/6MqwgPIiQaQ?si=LE9Tp8s-1wQ-OhBX\"\n",
    "}\n",
    "\n",
    "print(\"Available example videos:\")\n",
    "for name, url in example_videos.items():\n",
    "    print(f\"  {name}: {url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis Example\n",
    "\n",
    "Let's analyze one of the example videos. This will take a few minutes depending on your CPU and video length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select video to analyze\n",
    "video_name = \"bachata_demo_1\"\n",
    "video_url = example_videos[video_name]\n",
    "output_dir = Path(f\"./output/{video_name}\")\n",
    "\n",
    "print(f\"Analyzing: {video_url}\")\n",
    "print(f\"Output directory: {output_dir}\")\n",
    "print(\"\\nThis may take 5-15 minutes depending on your CPU...\")\n",
    "\n",
    "# Run analysis\n",
    "with BachataAnalyzer(config) as analyzer:\n",
    "    result = analyzer.analyze(video_url, output_dir)\n",
    "\n",
    "print(f\"\\nAnalysis complete!\")\n",
    "print(f\"Found {len(result.segments)} dance combinations\")\n",
    "print(f\"Total dance time: {result.get_total_dance_time():.1f}s\")\n",
    "print(f\"Dance coverage: {(result.get_total_dance_time() / result.duration_sec) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Summary\n",
    "\n",
    "Let's examine the analysis results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display results\n",
    "import json\n",
    "\n",
    "# Load JSON results\n",
    "json_path = output_dir / \"segments.json\"\n",
    "with open(json_path, 'r') as f:\n",
    "    results_data = json.load(f)\n",
    "\n",
    "print(f\"Video ID: {results_data['video_id']}\")\n",
    "print(f\"Duration: {results_data['duration_sec']:.1f} seconds\")\n",
    "print(f\"FPS: {results_data['fps']}\")\n",
    "print(f\"Total segments: {len(results_data['segments'])}\")\n",
    "\n",
    "# Display first few segments\n",
    "print(\"\\nFirst 5 segments:\")\n",
    "for i, segment in enumerate(results_data['segments'][:5]):\n",
    "    print(f\"\\n  {segment['tentative_name']}: {segment['start_sec']:.1f}s - {segment['end_sec']:.1f}s\")\n",
    "    print(f\"    Duration: {segment['end_sec'] - segment['start_sec']:.1f}s\")\n",
    "    print(f\"    Leader: {segment['leader_name']}, Follower: {segment['follower_name']}\")\n",
    "    print(f\"    Avg Speed: {segment['features']['avg_speed']:.4f}\")\n",
    "    print(f\"    Turns: {segment['features']['turns']}, Dip: {segment['features']['dip']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Analysis\n",
    "\n",
    "Let's visualize some of the extracted features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features for visualization\n",
    "segments = results_data['segments']\n",
    "\n",
    "# Create feature arrays\n",
    "speeds = [seg['features']['avg_speed'] for seg in segments]\n",
    "hand_distances = [seg['features']['hand_distance_avg'] for seg in segments]\n",
    "step_cadences = [seg['features']['step_cadence'] for seg in segments]\n",
    "durations = [seg['end_sec'] - seg['start_sec'] for seg in segments]\n",
    "turns = [seg['features']['turns'] for seg in segments]\n",
    "dips = [seg['features']['dip'] for seg in segments]\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "fig.suptitle('Dance Segment Features', fontsize=16)\n",
    "\n",
    "# Speed distribution\n",
    "axes[0, 0].hist(speeds, bins=20, alpha=0.7, color='blue')\n",
    "axes[0, 0].set_title('Average Speed Distribution')\n",
    "axes[0, 0].set_xlabel('Speed')\n",
    "axes[0, 0].set_ylabel('Count')\n",
    "\n",
    "# Hand distance distribution\n",
    "axes[0, 1].hist(hand_distances, bins=20, alpha=0.7, color='green')\n",
    "axes[0, 1].set_title('Hand Distance Distribution')\n",
    "axes[0, 1].set_xlabel('Hand Distance')\n",
    "axes[0, 1].set_ylabel('Count')\n",
    "\n",
    "# Step cadence distribution\n",
    "axes[0, 2].hist(step_cadences, bins=20, alpha=0.7, color='red')\n",
    "axes[0, 2].set_title('Step Cadence Distribution')\n",
    "axes[0, 2].set_xlabel('Step Cadence')\n",
    "axes[0, 2].set_ylabel('Count')\n",
    "\n",
    "# Duration distribution\n",
    "axes[1, 0].hist(durations, bins=20, alpha=0.7, color='purple')\n",
    "axes[1, 0].set_title('Segment Duration Distribution')\n",
    "axes[1, 0].set_xlabel('Duration (seconds)')\n",
    "axes[1, 0].set_ylabel('Count')\n",
    "\n",
    "# Turns and dips\n",
    "turn_count = sum(turns)\n",
    "dip_count = sum(dips)\n",
    "no_special = len(turns) - turn_count - dip_count\n",
    "\n",
    "axes[1, 1].bar(['Turns', 'Dips', 'Neither'], [turn_count, dip_count, no_special], \n",
    "               color=['orange', 'pink', 'gray'])\n",
    "axes[1, 1].set_title('Special Moves Count')\n",
    "axes[1, 1].set_ylabel('Count')\n",
    "\n",
    "# Timeline visualization\n",
    "segment_times = [(seg['start_sec'], seg['end_sec']) for seg in segments]\n",
    "for i, (start, end) in enumerate(segment_times):\n",
    "    color = 'red' if turns[i] else 'blue' if dips[i] else 'green'\n",
    "    axes[1, 2].barh(i, end - start, left=start, height=0.8, color=color, alpha=0.7)\n",
    "\n",
    "axes[1, 2].set_title('Dance Timeline')\n",
    "axes[1, 2].set_xlabel('Time (seconds)')\n",
    "axes[1, 2].set_ylabel('Segment')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print statistics\n",
    "print(f\"\\nFeature Statistics:\")\n",
    "print(f\"  Average speed: {np.mean(speeds):.4f} ± {np.std(speeds):.4f}\")\n",
    "print(f\"  Average hand distance: {np.mean(hand_distances):.4f} ± {np.std(hand_distances):.4f}\")\n",
    "print(f\"  Average segment duration: {np.mean(durations):.1f} ± {np.std(durations):.1f}s\")\n",
    "print(f\"  Segments with turns: {turn_count}/{len(segments)} ({100*turn_count/len(segments):.1f}%)\")\n",
    "print(f\"  Segments with dips: {dip_count}/{len(segments)} ({100*dip_count/len(segments):.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Summary\n",
    "\n",
    "Let's display the generated text summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display text summary\n",
    "summary_path = output_dir / \"summary.md\"\n",
    "with open(summary_path, 'r') as f:\n",
    "    summary_content = f.read()\n",
    "\n",
    "print(summary_content[:2000])  # Display first 2000 characters\n",
    "print(\"... (truncated for display)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotated Video\n",
    "\n",
    "If video generation was enabled, let's display the annotated video:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if annotated video exists\n",
    "video_path = output_dir / \"annotated.mp4\"\n",
    "\n",
    "if video_path.exists():\n",
    "    print(f\"Annotated video available: {video_path}\")\n",
    "    print(f\"Video size: {video_path.stat().st_size / (1024*1024):.1f} MB\")\n",
    "    \n",
    "    # Display video (works in Jupyter/Colab)\n",
    "    try:\n",
    "        display(Video(str(video_path), width=640, height=480))\n",
    "    except:\n",
    "        print(\"Video display not available in this environment\")\n",
    "        print(f\"You can download the video from: {video_path}\")\n",
    "else:\n",
    "    print(\"Annotated video not found. Video generation may have been disabled or failed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Analysis\n",
    "\n",
    "Let's analyze the performance and accuracy of our segmentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance metrics\n",
    "total_segments = len(segments)\n",
    "total_dance_time = result.get_total_dance_time()\n",
    "video_duration = result.duration_sec\n",
    "dance_coverage = (total_dance_time / video_duration) * 100\n",
    "avg_segment_length = total_dance_time / total_segments\n",
    "\n",
    "print(\"Performance Analysis:\")\n",
    "print(f\"  Total segments detected: {total_segments}\")\n",
    "print(f\"  Total dance time: {total_dance_time:.1f}s\")\n",
    "print(f\"  Video duration: {video_duration:.1f}s\")\n",
    "print(f\"  Dance coverage: {dance_coverage:.1f}%\")\n",
    "print(f\"  Average segment length: {avg_segment_length:.1f}s\")\n",
    "\n",
    "# Segment quality metrics\n",
    "quality_scores = []\n",
    "for seg in segments:\n",
    "    # Simple quality score based on movement and features\n",
    "    score = seg['features']['avg_speed'] * 10\n",
    "    if seg['features']['turns']:\n",
    "        score += 2\n",
    "    if seg['features']['dip']:\n",
    "        score += 3\n",
    "    quality_scores.append(score)\n",
    "\n",
    "print(f\"\\nSegment Quality:\")\n",
    "print(f\"  Average quality score: {np.mean(quality_scores):.2f} ± {np.std(quality_scores):.2f}\")\n",
    "print(f\"  Highest quality segment: {np.argmax(quality_scores) + 1}\")\n",
    "print(f\"  Lowest quality segment: {np.argmin(quality_scores) + 1}\")\n",
    "\n",
    "# Find most interesting segments\n",
    "fastest_segments = sorted(range(len(speeds)), key=lambda i: speeds[i], reverse=True)[:3]\n",
    "slowest_segments = sorted(range(len(speeds)), key=lambda i: speeds[i])[:3]\n",
    "\n",
    "print(f\"\\nMost Dynamic Segments:\")\n",
    "for i in fastest_segments:\n",
    "    seg = segments[i]\n",
    "    print(f\"  {seg['tentative_name']}: {seg['start_sec']:.1f}s-{seg['end_sec']:.1f}s (speed: {speeds[i]:.4f})\")\n",
    "\n",
    "print(f\"\\nSlowest Segments:\")\n",
    "for i in slowest_segments:\n",
    "    seg = segments[i]\n",
    "    print(f\"  {seg['tentative_name']}: {seg['start_sec']:.1f}s-{seg['end_sec']:.1f}s (speed: {speeds[i]:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Analysis\n",
    "\n",
    "You can analyze other videos by modifying the URL below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze a custom video (uncomment and modify)\n",
    "# custom_url = \"https://www.youtube.com/watch?v=YOUR_VIDEO_ID\"\n",
    "# custom_output = Path(\"./output/custom_analysis\")\n",
    "\n",
    "# with BachataAnalyzer(config) as analyzer:\n",
    "#     custom_result = analyzer.analyze(custom_url, custom_output)\n",
    "#     print(f\"Found {len(custom_result.segments)} combinations in custom video\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration Tuning\n",
    "\n",
    "Experiment with different configurations to see how they affect the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different configurations\n",
    "configs_to_test = [\n",
    "    {\"name\": \"Fast Processing\", \"fps\": 8, \"max_width\": 720},\n",
    "    {\"name\": \"High Quality\", \"fps\": 15, \"max_width\": 1280},\n",
    "    {\"name\": \"Sensitive Segmentation\", \"min_segment_sec\": 2.0, \"change_point_sensitivity\": 1.2},\n",
    "    {\"name\": \"Conservative Segmentation\", \"min_segment_sec\": 6.0, \"change_point_sensitivity\": 0.5}\n",
    "]\n",
    "\n",
    "# Uncomment to test different configs\n",
    "# for config_params in configs_to_test:\n",
    "#     print(f\"\\nTesting: {config_params['name']}\")\n",
    "#     test_config = AnalysisConfig(**{k: v for k, v in config_params.items() if k != 'name'})\n",
    "#     \n",
    "#     test_output = Path(f\"./output/test_{config_params['name'].lower().replace(' ', '_')}\")\n",
    "#     \n",
    "#     with BachataAnalyzer(test_config) as analyzer:\n",
    "#         test_result = analyzer.analyze(video_url, test_output)\n",
    "#         print(f\"  Segments found: {len(test_result.segments)}\")\n",
    "#         print(f\"  Processing time: (varies by config)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated the complete Bachata Video Professor pipeline:\n",
    "\n",
    "### Key Features:\n",
    "- **CPU-only processing**: Works on standard laptops without GPU\n",
    "- **Multi-person tracking**: Automatically identifies the primary dancing couple\n",
    "- **Unsupervised segmentation**: Detects dance combinations without manual labeling\n",
    "- **Multiple outputs**: JSON data, human-readable summary, and annotated video\n",
    "- **Configurable parameters**: Adjust speed vs. accuracy tradeoffs\n",
    "\n",
    "### Usage Tips:\n",
    "- Lower FPS and resolution for faster processing\n",
    "- Adjust segment length based on dance style\n",
    "- Use temporal smoothing for more stable pose tracking\n",
    "- Experiment with change point sensitivity for different dance styles\n",
    "\n",
    "### Next Steps:\n",
    "- Try with different Bachata videos\n",
    "- Adjust parameters for your specific use case\n",
    "- Integrate with your own dance analysis workflow\n",
    "- Extend with custom features or classifiers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}