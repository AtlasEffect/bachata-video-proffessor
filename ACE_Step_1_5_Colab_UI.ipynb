{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AtlasEffect/bachata-video-proffessor/blob/main/ACE_Step_1_5_Colab_UI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhi7V5yNW3SL"
      },
      "source": [
        "# üéµ ACE-Step v1.5 - Google Colab Launcher\n",
        "### üî¥ Brought to you by [AI With Chucky](https://youtube.com/@AIWithChucky)\n",
        "\n",
        "**Notes:**\n",
        "- This requires a GPU runtime (T4 is usually sufficient).\n",
        "- The first run will take a few minutes to download the models (approx 10GB).\n",
        "- **Wait for the link ending in `gradio.live` to appear at the bottom.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cW6yMT16W3SP",
        "outputId": "e17cc61f-54c0-4f1e-becb-59d00fc308cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Repository already exists.\n",
            "Working directory set to: /content/Ace-Step-v1.5\n",
            "Patching requirements.txt...\n",
            "Patching app.py to enable public sharing...\n",
            "‚úÖ Setup phase 1 complete.\n"
          ]
        }
      ],
      "source": [
        "# @title 1. Clone Repository & Patch Dependencies\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# 1. Clone the Hugging Face Space\n",
        "if not os.path.exists(\"Ace-Step-v1.5\"):\n",
        "    print(\"Cloning ACE-Step v1.5 repository...\")\n",
        "    !git clone https://huggingface.co/spaces/ACE-Step/Ace-Step-v1.5\n",
        "else:\n",
        "    print(\"Repository already exists.\")\n",
        "\n",
        "# 2. Force Change Directory\n",
        "# This ensures subsequent commands run inside the folder\n",
        "os.chdir(\"/content/Ace-Step-v1.5\")\n",
        "print(f\"Working directory set to: {os.getcwd()}\")\n",
        "\n",
        "# 3. Patch requirements.txt\n",
        "# The original file asks for torch>=2.9.1 (future version) for Linux, which fails install.\n",
        "# We relax this to allow the current stable torch version.\n",
        "print(\"Patching requirements.txt...\")\n",
        "!sed -i 's/torch>=2.9.1/torch/g' requirements.txt\n",
        "\n",
        "# 4. Patch app.py for Public Access\n",
        "# By default, share=False. We change it to share=True to get a public Gradio link.\n",
        "print(\"Patching app.py to enable public sharing...\")\n",
        "!sed -i 's/share=False/share=True/g' app.py\n",
        "\n",
        "print(\"‚úÖ Setup phase 1 complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fQgzgby3W3SR",
        "outputId": "2775bc96-2663-4564-db57-01280c2b40d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing Python dependencies... (This may take 3-5 minutes)\n",
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu121\n",
            "Ignoring triton-windows: markers 'sys_platform == \"win32\"' don't match your environment\n",
            "Ignoring flash-attn: markers 'sys_platform == \"win32\" and python_version == \"3.11\" and platform_machine == \"AMD64\"' don't match your environment\n",
            "Ignoring flash-attn: markers 'sys_platform == \"linux\" and python_version == \"3.11\"' don't match your environment\n",
            "Requirement already satisfied: torch==2.9.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (2.9.1)\n",
            "Requirement already satisfied: torchaudio==2.9.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (2.9.1)\n",
            "Requirement already satisfied: torchvision==0.24.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 4)) (0.24.1)\n",
            "Requirement already satisfied: transformers<4.58.0,>=4.51.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (4.57.6)\n",
            "Requirement already satisfied: diffusers in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 8)) (0.36.0)\n",
            "Requirement already satisfied: gradio==6.2.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 9)) (6.2.0)\n",
            "Requirement already satisfied: matplotlib>=3.7.5 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 10)) (3.10.0)\n",
            "Requirement already satisfied: scipy>=1.10.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 11)) (1.16.3)\n",
            "Requirement already satisfied: soundfile>=0.13.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 12)) (0.13.1)\n",
            "Requirement already satisfied: ffmpeg-python in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 13)) (0.2.0)\n",
            "Requirement already satisfied: loguru>=0.7.3 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 14)) (0.7.3)\n",
            "Requirement already satisfied: einops>=0.8.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 15)) (0.8.2)\n",
            "Requirement already satisfied: accelerate>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 16)) (1.12.0)\n",
            "Requirement already satisfied: fastapi>=0.110.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 17)) (0.133.0)\n",
            "Requirement already satisfied: diskcache in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 18)) (5.6.3)\n",
            "Requirement already satisfied: uvicorn>=0.27.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.27.0->-r requirements.txt (line 19)) (0.41.0)\n",
            "Requirement already satisfied: numba>=0.63.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 20)) (0.64.0)\n",
            "Requirement already satisfied: vector-quantize-pytorch>=1.27.15 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 21)) (1.27.21)\n",
            "Requirement already satisfied: peft>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 25)) (0.18.1)\n",
            "Requirement already satisfied: lightning>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 26)) (2.6.1)\n",
            "Requirement already satisfied: triton>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 30)) (3.5.1)\n",
            "Requirement already satisfied: kernels in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 34)) (0.12.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 35)) (3.6.0)\n",
            "Requirement already satisfied: spaces in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 38)) (0.47.0)\n",
            "Requirement already satisfied: huggingface_hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 39)) (0.36.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->-r requirements.txt (line 2)) (3.24.3)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->-r requirements.txt (line 2)) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->-r requirements.txt (line 2)) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->-r requirements.txt (line 2)) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->-r requirements.txt (line 2)) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->-r requirements.txt (line 2)) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->-r requirements.txt (line 2)) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->-r requirements.txt (line 2)) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->-r requirements.txt (line 2)) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->-r requirements.txt (line 2)) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->-r requirements.txt (line 2)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->-r requirements.txt (line 2)) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->-r requirements.txt (line 2)) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->-r requirements.txt (line 2)) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->-r requirements.txt (line 2)) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->-r requirements.txt (line 2)) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->-r requirements.txt (line 2)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->-r requirements.txt (line 2)) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->-r requirements.txt (line 2)) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->-r requirements.txt (line 2)) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->-r requirements.txt (line 2)) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->-r requirements.txt (line 2)) (1.13.1.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision==0.24.1->-r requirements.txt (line 4)) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision==0.24.1->-r requirements.txt (line 4)) (11.3.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio==6.2.0->-r requirements.txt (line 9)) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio==6.2.0->-r requirements.txt (line 9)) (4.12.1)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio==6.2.0->-r requirements.txt (line 9)) (1.2.0)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio==6.2.0->-r requirements.txt (line 9)) (1.0.0)\n",
            "Requirement already satisfied: gradio-client==2.0.2 in /usr/local/lib/python3.12/dist-packages (from gradio==6.2.0->-r requirements.txt (line 9)) (2.0.2)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio==6.2.0->-r requirements.txt (line 9)) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio==6.2.0->-r requirements.txt (line 9)) (0.28.1)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio==6.2.0->-r requirements.txt (line 9)) (3.0.3)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio==6.2.0->-r requirements.txt (line 9)) (3.11.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio==6.2.0->-r requirements.txt (line 9)) (26.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio==6.2.0->-r requirements.txt (line 9)) (2.2.2)\n",
            "Requirement already satisfied: pydantic<=3.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio==6.2.0->-r requirements.txt (line 9)) (2.12.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio==6.2.0->-r requirements.txt (line 9)) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio==6.2.0->-r requirements.txt (line 9)) (0.0.22)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio==6.2.0->-r requirements.txt (line 9)) (6.0.3)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.7 in /usr/local/lib/python3.12/dist-packages (from gradio==6.2.0->-r requirements.txt (line 9)) (0.1.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio==6.2.0->-r requirements.txt (line 9)) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio==6.2.0->-r requirements.txt (line 9)) (0.52.1)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio==6.2.0->-r requirements.txt (line 9)) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio==6.2.0->-r requirements.txt (line 9)) (0.24.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<4.58.0,>=4.51.0->-r requirements.txt (line 7)) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers<4.58.0,>=4.51.0->-r requirements.txt (line 7)) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<4.58.0,>=4.51.0->-r requirements.txt (line 7)) (0.22.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<4.58.0,>=4.51.0->-r requirements.txt (line 7)) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers<4.58.0,>=4.51.0->-r requirements.txt (line 7)) (4.67.3)\n",
            "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.12/dist-packages (from diffusers->-r requirements.txt (line 8)) (8.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.5->-r requirements.txt (line 10)) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.5->-r requirements.txt (line 10)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.5->-r requirements.txt (line 10)) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.5->-r requirements.txt (line 10)) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.5->-r requirements.txt (line 10)) (3.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.5->-r requirements.txt (line 10)) (2.9.0.post0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile>=0.13.1->-r requirements.txt (line 12)) (2.0.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.12/dist-packages (from ffmpeg-python->-r requirements.txt (line 13)) (1.0.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate>=1.12.0->-r requirements.txt (line 16)) (5.9.5)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from fastapi>=0.110.0->-r requirements.txt (line 17)) (0.4.2)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi>=0.110.0->-r requirements.txt (line 17)) (0.0.4)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn>=0.27.0->uvicorn[standard]>=0.27.0->-r requirements.txt (line 19)) (8.3.1)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn>=0.27.0->uvicorn[standard]>=0.27.0->-r requirements.txt (line 19)) (0.16.0)\n",
            "Requirement already satisfied: llvmlite<0.47,>=0.46.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.63.1->-r requirements.txt (line 20)) (0.46.0)\n",
            "Requirement already satisfied: einx>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from vector-quantize-pytorch>=1.27.15->-r requirements.txt (line 21)) (0.3.0)\n",
            "Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from lightning>=2.0.0->-r requirements.txt (line 26)) (0.15.3)\n",
            "Requirement already satisfied: torchmetrics<3.0,>0.7.0 in /usr/local/lib/python3.12/dist-packages (from lightning>=2.0.0->-r requirements.txt (line 26)) (1.8.2)\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.12/dist-packages (from lightning>=2.0.0->-r requirements.txt (line 26)) (2.6.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.20.0->-r requirements.txt (line 39)) (1.3.0)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.27.0->-r requirements.txt (line 19)) (0.7.1)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.27.0->-r requirements.txt (line 19)) (1.2.1)\n",
            "Requirement already satisfied: uvloop>=0.15.1 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.27.0->-r requirements.txt (line 19)) (0.22.1)\n",
            "Requirement already satisfied: watchfiles>=0.20 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.27.0->-r requirements.txt (line 19)) (1.1.1)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.27.0->-r requirements.txt (line 19)) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio==6.2.0->-r requirements.txt (line 9)) (3.11)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile>=0.13.1->-r requirements.txt (line 12)) (3.0)\n",
            "Requirement already satisfied: frozendict in /usr/local/lib/python3.12/dist-packages (from einx>=0.3.0->vector-quantize-pytorch>=1.27.15->-r requirements.txt (line 21)) (2.4.7)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<2028.0,>=2022.5.0->lightning>=2.0.0->-r requirements.txt (line 26)) (3.13.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio==6.2.0->-r requirements.txt (line 9)) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio==6.2.0->-r requirements.txt (line 9)) (1.0.9)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio==6.2.0->-r requirements.txt (line 9)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio==6.2.0->-r requirements.txt (line 9)) (2025.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<=3.0,>=2.0->gradio==6.2.0->-r requirements.txt (line 9)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<=3.0,>=2.0->gradio==6.2.0->-r requirements.txt (line 9)) (2.41.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.7.5->-r requirements.txt (line 10)) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers<4.58.0,>=4.51.0->-r requirements.txt (line 7)) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers<4.58.0,>=4.51.0->-r requirements.txt (line 7)) (2.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch==2.9.1->-r requirements.txt (line 2)) (1.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio==6.2.0->-r requirements.txt (line 9)) (1.5.4)\n",
            "Requirement already satisfied: rich>=12.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio==6.2.0->-r requirements.txt (line 9)) (13.9.4)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib_metadata->diffusers->-r requirements.txt (line 8)) (3.23.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2028.0,>=2022.5.0->lightning>=2.0.0->-r requirements.txt (line 26)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2028.0,>=2022.5.0->lightning>=2.0.0->-r requirements.txt (line 26)) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2028.0,>=2022.5.0->lightning>=2.0.0->-r requirements.txt (line 26)) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2028.0,>=2022.5.0->lightning>=2.0.0->-r requirements.txt (line 26)) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2028.0,>=2022.5.0->lightning>=2.0.0->-r requirements.txt (line 26)) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2028.0,>=2022.5.0->lightning>=2.0.0->-r requirements.txt (line 26)) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2028.0,>=2022.5.0->lightning>=2.0.0->-r requirements.txt (line 26)) (1.22.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.3.0->typer<1.0,>=0.12->gradio==6.2.0->-r requirements.txt (line 9)) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.3.0->typer<1.0,>=0.12->gradio==6.2.0->-r requirements.txt (line 9)) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=12.3.0->typer<1.0,>=0.12->gradio==6.2.0->-r requirements.txt (line 9)) (0.1.2)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 37 not upgraded.\n",
            "‚úÖ Dependencies installed.\n"
          ]
        }
      ],
      "source": [
        "# @title 2. Install Dependencies\n",
        "import os\n",
        "\n",
        "# Ensure we are in the correct folder\n",
        "if os.getcwd() != \"/content/Ace-Step-v1.5\":\n",
        "    os.chdir(\"/content/Ace-Step-v1.5\")\n",
        "\n",
        "print(\"Installing Python dependencies... (This may take 3-5 minutes)\")\n",
        "\n",
        "# Install dependencies with CUDA support\n",
        "# We skip strict version checks for some libs to avoid Colab conflicts\n",
        "!pip install -r requirements.txt --extra-index-url https://download.pytorch.org/whl/cu121\n",
        "\n",
        "# Install system dependency for audio processing\n",
        "!apt-get install -y ffmpeg\n",
        "\n",
        "print(\"‚úÖ Dependencies installed.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/Ace-Step-v1.5\n",
        "!pip install -e ./acestep/third_parts/nano-vllm"
      ],
      "metadata": {
        "id": "4KDasyGMPyTX",
        "outputId": "276740ef-caf1-4f0c-f991-d3d4e5dddf9f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Obtaining file:///content/Ace-Step-v1.5/acestep/third_parts/nano-vllm\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from nano-vllm==0.2.0) (2.9.1)\n",
            "Requirement already satisfied: triton>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from nano-vllm==0.2.0) (3.5.1)\n",
            "Requirement already satisfied: transformers>=4.51.0 in /usr/local/lib/python3.12/dist-packages (from nano-vllm==0.2.0) (4.57.6)\n",
            "Requirement already satisfied: flash-attn in /usr/local/lib/python3.12/dist-packages (from nano-vllm==0.2.0) (2.8.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from nano-vllm==0.2.0) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->nano-vllm==0.2.0) (3.24.3)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->nano-vllm==0.2.0) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->nano-vllm==0.2.0) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->nano-vllm==0.2.0) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->nano-vllm==0.2.0) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->nano-vllm==0.2.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->nano-vllm==0.2.0) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->nano-vllm==0.2.0) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->nano-vllm==0.2.0) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->nano-vllm==0.2.0) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->nano-vllm==0.2.0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->nano-vllm==0.2.0) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->nano-vllm==0.2.0) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->nano-vllm==0.2.0) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->nano-vllm==0.2.0) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->nano-vllm==0.2.0) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->nano-vllm==0.2.0) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->nano-vllm==0.2.0) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->nano-vllm==0.2.0) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->nano-vllm==0.2.0) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->nano-vllm==0.2.0) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->nano-vllm==0.2.0) (1.13.1.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.51.0->nano-vllm==0.2.0) (0.36.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.51.0->nano-vllm==0.2.0) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.51.0->nano-vllm==0.2.0) (26.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.51.0->nano-vllm==0.2.0) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.51.0->nano-vllm==0.2.0) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers>=4.51.0->nano-vllm==0.2.0) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.51.0->nano-vllm==0.2.0) (0.22.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.51.0->nano-vllm==0.2.0) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.51.0->nano-vllm==0.2.0) (4.67.3)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from flash-attn->nano-vllm==0.2.0) (0.8.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.51.0->nano-vllm==0.2.0) (1.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.4.0->nano-vllm==0.2.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.4.0->nano-vllm==0.2.0) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.51.0->nano-vllm==0.2.0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.51.0->nano-vllm==0.2.0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.51.0->nano-vllm==0.2.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.51.0->nano-vllm==0.2.0) (2026.1.4)\n",
            "Building wheels for collected packages: nano-vllm\n",
            "  Building editable for nano-vllm (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nano-vllm: filename=nano_vllm-0.2.0-0.editable-py3-none-any.whl size=5037 sha256=bd5673f69c087c922b32048198fbd3965b32e18b5b52043fa4f5e3fff17e3722\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-atg1s5w5/wheels/0c/95/fd/55ed745fe219a1900e427f7db76e5eef5c2e3c3e0cfdaa8a7e\n",
            "Successfully built nano-vllm\n",
            "Installing collected packages: nano-vllm\n",
            "  Attempting uninstall: nano-vllm\n",
            "    Found existing installation: nano-vllm 0.2.0\n",
            "    Uninstalling nano-vllm-0.2.0:\n",
            "      Successfully uninstalled nano-vllm-0.2.0\n",
            "Successfully installed nano-vllm-0.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "model_dir = \"/content/Ace-Step-v1.5/data/checkpoints/acestep-5Hz-lm-1.7B\"\n",
        "config_path = os.path.join(model_dir, \"config.json\")\n",
        "\n",
        "if os.path.exists(config_path):\n",
        "    with open(config_path, 'r') as f:\n",
        "        config = json.load(f)\n",
        "\n",
        "    # Remove or set to false any flash attn flags\n",
        "    if \"attn_implementation\" in config:\n",
        "        del config[\"attn_implementation\"]  # or set to \"eager\"\n",
        "    if \"_attn_implementation\" in config:  # sometimes hidden\n",
        "        del config[\"_attn_implementation\"]\n",
        "    config[\"use_flash_attn\"] = False       # if present\n",
        "    config[\"attn_implementation\"] = \"eager\"  # or \"sdpa\"\n",
        "\n",
        "    with open(config_path, 'w') as f:\n",
        "        json.dump(config, f, indent=2)\n",
        "\n",
        "    print(\"‚úÖ Patched config.json to disable flash attention\")\n",
        "else:\n",
        "    print(\"config.json not found ‚Äî skip patch\")"
      ],
      "metadata": {
        "id": "TBewijI3dF-A",
        "outputId": "63498c00-693b-438b-964e-e5c65c9a94cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Patched config.json to disable flash attention\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OnuKw_9XW3ST",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04af8140-151a-4f1b-9f6c-4252f2971d0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚è≥ Starting Model Download... (This prevents timeouts)\n",
            "Initializing download sequence...\n",
            "2026-02-27 09:37:27.207577: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1772185047.228694   25803 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1772185047.236022   25803 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1772185047.254425   25803 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1772185047.254467   25803 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1772185047.254472   25803 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1772185047.254476   25803 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-02-27 09:37:27.259232: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Flax classes are deprecated and will be removed in Diffusers v1.0.0. We recommend migrating to PyTorch classes or pinning your version of Diffusers.\n",
            "Flax classes are deprecated and will be removed in Diffusers v1.0.0. We recommend migrating to PyTorch classes or pinning your version of Diffusers.\n",
            "Downloading ACE-Step v1.5 Unified Repo (This includes DiT and LLM)...\n",
            "This may take a while (approx 10GB)...\n",
            "\u001b[32m2026-02-27 09:37:32.974\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macestep.handler\u001b[0m:\u001b[36m_ensure_model_downloaded\u001b[0m:\u001b[36m168\u001b[0m - \u001b[1mModel /content/Ace-Step-v1.5 already exists at /content/Ace-Step-v1.5\u001b[0m\n",
            "\n",
            "‚úÖ Download complete.\n",
            "============================================================\n",
            "üöÄ Models ready. Launching ACE-Step Interface...\n",
            "üîó Click the public link ending in 'gradio.live' below once it appears.\n",
            "============================================================\n",
            "2026-02-27 09:37:43.215730: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1772185063.236813   25888 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1772185063.243820   25888 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1772185063.261559   25888 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1772185063.261584   25888 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1772185063.261588   25888 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1772185063.261591   25888 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-02-27 09:37:43.266014: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Flax classes are deprecated and will be removed in Diffusers v1.0.0. We recommend migrating to PyTorch classes or pinning your version of Diffusers.\n",
            "Flax classes are deprecated and will be removed in Diffusers v1.0.0. We recommend migrating to PyTorch classes or pinning your version of Diffusers.\n",
            "Using local storage (non-persistent): /content/Ace-Step-v1.5/data\n",
            "Note: To enable persistent storage, configure it in HuggingFace Space settings\n",
            "Detected GPU memory: 14.56 GB (< 16GB)\n",
            "Auto-enabling CPU offload to reduce GPU memory usage\n",
            "Creating handlers...\n",
            "Service mode configuration:\n",
            "  DiT model 1: acestep-v15-turbo\n",
            "  LM model: acestep-5Hz-lm-1.7B\n",
            "  Backend: pt\n",
            "  Offload to CPU: True\n",
            "  DEBUG_UI: False\n",
            "  ZeroGPU: False\n",
            "  Flash Attention: True\n",
            "Initializing DiT model 1: acestep-v15-turbo...\n",
            "\u001b[32m2026-02-27 09:37:53.596\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macestep.handler\u001b[0m:\u001b[36minitialize_service\u001b[0m:\u001b[36m463\u001b[0m - \u001b[1m[initialize_service] Attempting to load model with attention implementation: kernels-community/flash-attn3\u001b[0m\n",
            "Fetching 7 files: 100% 7/7 [00:00<00:00, 61551.63steps/s]\n",
            "Fetching 7 files: 100% 7/7 [00:00<00:00, 8827.46steps/s]\n",
            "Fetching 7 files: 100% 7/7 [00:00<00:00, 8648.05steps/s]\n",
            "Fetching 7 files: 100% 7/7 [00:00<00:00, 10778.31steps/s]\n",
            "Fetching 7 files: 100% 7/7 [00:00<00:00, 7551.47steps/s]\n",
            "Fetching 7 files: 100% 7/7 [00:00<00:00, 11734.66steps/s]\n",
            "Fetching 7 files: 100% 7/7 [00:00<00:00, 9471.01steps/s]\n",
            "Fetching 7 files: 100% 7/7 [00:00<00:00, 53576.88steps/s]\n",
            "\u001b[32m2026-02-27 09:37:56.851\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macestep.handler\u001b[0m:\u001b[36minitialize_service\u001b[0m:\u001b[36m486\u001b[0m - \u001b[1m[initialize_service] Keeping main model on cuda (persistent)\u001b[0m\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "Fetching 7 files: 100% 7/7 [00:00<00:00, 76858.97steps/s]\n",
            "\u001b[32m2026-02-27 09:38:18.349\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macestep.handler\u001b[0m:\u001b[36minitialize_service\u001b[0m:\u001b[36m574\u001b[0m - \u001b[1m[initialize_service] Text encoder loaded with kernels-community/flash-attn3\u001b[0m\n",
            "DiT model 1 initialized successfully\n",
            "Initializing 5Hz LM: acestep-5Hz-lm-1.7B...\n",
            "\u001b[32m2026-02-27 09:38:18.356\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macestep.llm_inference\u001b[0m:\u001b[36minitialize\u001b[0m:\u001b[36m374\u001b[0m - \u001b[1m[LLM Init Debug] IS_ZEROGPU=False, IS_HUGGINGFACE_SPACE=False\u001b[0m\n",
            "\u001b[32m2026-02-27 09:38:18.356\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macestep.llm_inference\u001b[0m:\u001b[36minitialize\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1m[LLM Init Debug] torch.cuda.is_available()=True\u001b[0m\n",
            "\u001b[32m2026-02-27 09:38:18.356\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macestep.llm_inference\u001b[0m:\u001b[36minitialize\u001b[0m:\u001b[36m376\u001b[0m - \u001b[1m[LLM Init Debug] device=cuda, offload_to_cpu=True\u001b[0m\n",
            "\u001b[32m2026-02-27 09:38:18.356\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macestep.llm_inference\u001b[0m:\u001b[36minitialize\u001b[0m:\u001b[36m392\u001b[0m - \u001b[1mloading 5Hz LM tokenizer... it may take 80~90s\u001b[0m\n",
            "\u001b[32m2026-02-27 09:38:47.989\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macestep.llm_inference\u001b[0m:\u001b[36minitialize\u001b[0m:\u001b[36m396\u001b[0m - \u001b[1m5Hz LM tokenizer loaded successfully in 29.63 seconds\u001b[0m\n",
            "\u001b[32m2026-02-27 09:38:47.989\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macestep.llm_inference\u001b[0m:\u001b[36minitialize\u001b[0m:\u001b[36m400\u001b[0m - \u001b[1mInitializing constrained decoding processor...\u001b[0m\n",
            "\u001b[32m2026-02-27 09:38:49.663\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36macestep.constrained_logits_processor\u001b[0m:\u001b[36m_precompute_audio_code_tokens\u001b[0m:\u001b[36m545\u001b[0m - \u001b[33m\u001b[1mFound 1535 audio code tokens with values outside valid range [0, 63999]\u001b[0m\n",
            "\u001b[32m2026-02-27 09:38:53.924\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macestep.llm_inference\u001b[0m:\u001b[36minitialize\u001b[0m:\u001b[36m407\u001b[0m - \u001b[1mConstrained processor initialized in 5.94 seconds\u001b[0m\n",
            "\u001b[32m2026-02-27 09:38:53.924\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macestep.llm_inference\u001b[0m:\u001b[36m_load_pytorch_model\u001b[0m:\u001b[36m237\u001b[0m - \u001b[1m[LLM Load] Attempting to load model with attention implementation: kernels-community/flash-attn3\u001b[0m\n",
            "Fetching 7 files: 100% 7/7 [00:00<00:00, 98194.41steps/s]\n",
            "Fetching 7 files: 100% 7/7 [00:00<00:00, 8173.76steps/s]\n",
            "\u001b[32m2026-02-27 09:38:54.753\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macestep.llm_inference\u001b[0m:\u001b[36m_load_pytorch_model\u001b[0m:\u001b[36m251\u001b[0m - \u001b[1m[LLM Load Debug] Model loaded with kernels-community/flash-attn3, initial device: cpu\u001b[0m\n",
            "\u001b[32m2026-02-27 09:38:54.758\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macestep.llm_inference\u001b[0m:\u001b[36m_load_pytorch_model\u001b[0m:\u001b[36m256\u001b[0m - \u001b[1m[LLM Load Debug] After .to(), model device: cpu\u001b[0m\n",
            "\u001b[32m2026-02-27 09:38:54.760\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macestep.llm_inference\u001b[0m:\u001b[36m_load_pytorch_model\u001b[0m:\u001b[36m262\u001b[0m - \u001b[1m5Hz LM initialized successfully using PyTorch backend on cuda\u001b[0m\n",
            "5Hz LM initialized successfully\n",
            "Service initialization completed!\n",
            "Creating Gradio interface...\n",
            "Enabling queue for multi-user support...\n",
            "Launching server on 0.0.0.0:7860...\n",
            "* Running on local URL:  http://0.0.0.0:7860\n",
            "* Running on public URL: https://4be98b84127afdbb1b.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n",
            "\u001b[32m2026-02-27 09:42:31.196\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macestep.inference\u001b[0m:\u001b[36mcreate_sample\u001b[0m:\u001b[36m914\u001b[0m - \u001b[1m[create_sample Debug] Entry: IS_HUGGINGFACE_SPACE=False\u001b[0m\n",
            "\u001b[32m2026-02-27 09:42:31.196\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macestep.inference\u001b[0m:\u001b[36mcreate_sample\u001b[0m:\u001b[36m915\u001b[0m - \u001b[1m[create_sample Debug] torch.cuda.is_available()=True\u001b[0m\n",
            "\u001b[32m2026-02-27 09:42:31.196\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macestep.inference\u001b[0m:\u001b[36mcreate_sample\u001b[0m:\u001b[36m917\u001b[0m - \u001b[1m[create_sample Debug] torch.cuda.current_device()=0\u001b[0m\n",
            "\u001b[32m2026-02-27 09:42:31.196\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macestep.inference\u001b[0m:\u001b[36mcreate_sample\u001b[0m:\u001b[36m918\u001b[0m - \u001b[1m[create_sample Debug] llm_handler.device=cuda, llm_handler.offload_to_cpu=True\u001b[0m\n",
            "\u001b[32m2026-02-27 09:42:31.196\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macestep.inference\u001b[0m:\u001b[36mcreate_sample\u001b[0m:\u001b[36m921\u001b[0m - \u001b[1m[create_sample Debug] Model device: cpu\u001b[0m\n",
            "\u001b[32m2026-02-27 09:42:31.196\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macestep.llm_inference\u001b[0m:\u001b[36mcreate_sample_from_query\u001b[0m:\u001b[36m1648\u001b[0m - \u001b[1mCreating sample from query: bachata... (instrumental=[], vocal_language=unknown)\u001b[0m\n",
            "\u001b[32m2026-02-27 09:42:31.222\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36macestep.llm_inference\u001b[0m:\u001b[36mcreate_sample_from_query\u001b[0m:\u001b[36m1655\u001b[0m - \u001b[34m\u001b[1mFormatted prompt for inspiration: <|im_start|>system\n",
            "# Instruction\n",
            "Expand the user's input into a more detailed and specific musical description:\n",
            "\n",
            "<|im_end|>\n",
            "<|im_start|>user\n",
            "bachata\n",
            "\n",
            "instrumental: false<|im_end|>\n",
            "<|im_start|>assistant\n",
            "\u001b[0m\n",
            "\u001b[32m2026-02-27 09:42:31.223\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36macestep.constrained_logits_processor\u001b[0m:\u001b[36mset_target_duration\u001b[0m:\u001b[36m1269\u001b[0m - \u001b[34m\u001b[1mTarget duration cleared, no duration constraint\u001b[0m\n",
            "\u001b[32m2026-02-27 09:42:31.224\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36macestep.constrained_logits_processor\u001b[0m:\u001b[36mset_user_metadata\u001b[0m:\u001b[36m427\u001b[0m - \u001b[34m\u001b[1mNo user-provided metadata, all fields will be generated\u001b[0m\n",
            "\u001b[32m2026-02-27 09:42:31.224\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macestep.llm_inference\u001b[0m:\u001b[36m_load_model_context\u001b[0m:\u001b[36m2379\u001b[0m - \u001b[1m[_load_model_context Debug] Entry: offload_to_cpu=True, backend=pt, self.device=cuda\u001b[0m\n",
            "\u001b[32m2026-02-27 09:42:31.224\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macestep.llm_inference\u001b[0m:\u001b[36m_load_model_context\u001b[0m:\u001b[36m2380\u001b[0m - \u001b[1m[_load_model_context Debug] torch.cuda.is_available()=True, IS_ZEROGPU=False\u001b[0m\n",
            "\u001b[32m2026-02-27 09:42:31.224\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macestep.llm_inference\u001b[0m:\u001b[36m_load_model_context\u001b[0m:\u001b[36m2385\u001b[0m - \u001b[1m[_load_model_context Debug] Model current device: cpu\u001b[0m\n",
            "\u001b[32m2026-02-27 09:42:31.224\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macestep.llm_inference\u001b[0m:\u001b[36m_load_model_context\u001b[0m:\u001b[36m2397\u001b[0m - \u001b[1m[_load_model_context Debug] Moving model from CPU to cuda\u001b[0m\n",
            "\u001b[32m2026-02-27 09:42:40.587\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macestep.llm_inference\u001b[0m:\u001b[36m_load_model_context\u001b[0m:\u001b[36m2399\u001b[0m - \u001b[1m[_load_model_context Debug] Model now on: cuda:0\u001b[0m\n",
            "\u001b[32m2026-02-27 09:42:40.587\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macestep.llm_inference\u001b[0m:\u001b[36m_load_model_context\u001b[0m:\u001b[36m2417\u001b[0m - \u001b[1mLoading LLM to cuda\u001b[0m\n",
            "\u001b[32m2026-02-27 09:42:40.597\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macestep.llm_inference\u001b[0m:\u001b[36m_load_model_context\u001b[0m:\u001b[36m2422\u001b[0m - \u001b[1mLoaded LLM to cuda in 0.0091s\u001b[0m\n",
            "\u001b[32m2026-02-27 09:42:40.597\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macestep.llm_inference\u001b[0m:\u001b[36m_run_pt_single\u001b[0m:\u001b[36m645\u001b[0m - \u001b[1m[_run_pt_single Debug] Inputs moved to model device: cuda:0\u001b[0m\n",
            "\u001b[32m2026-02-27 09:42:40.597\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macestep.llm_inference\u001b[0m:\u001b[36m_run_pt_single\u001b[0m:\u001b[36m646\u001b[0m - \u001b[1m[_run_pt_single Debug] Input actual device: cuda:0\u001b[0m\n",
            "\u001b[32m2026-02-27 09:42:41.120\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macestep.llm_inference\u001b[0m:\u001b[36m_load_model_context\u001b[0m:\u001b[36m2428\u001b[0m - \u001b[1mOffloading LLM to CPU\u001b[0m\n",
            "\u001b[32m2026-02-27 09:42:44.315\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macestep.llm_inference\u001b[0m:\u001b[36m_load_model_context\u001b[0m:\u001b[36m2434\u001b[0m - \u001b[1mOffloaded LLM to CPU in 3.1947s\u001b[0m\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/queueing.py\", line 766, in process_events\n",
            "    response = await route_utils.call_process_api(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/route_utils.py\", line 355, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/blocks.py\", line 2147, in process_api\n",
            "    result = await self.call_function(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/blocks.py\", line 1641, in call_function\n",
            "    prediction = await utils.async_iteration(iterator)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/utils.py\", line 859, in async_iteration\n",
            "    return await anext(iterator)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/utils.py\", line 850, in __anext__\n",
            "    return await anyio.to_thread.run_sync(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/anyio/to_thread.py\", line 63, in run_sync\n",
            "    return await get_async_backend().run_sync_in_worker_thread(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/anyio/_backends/_asyncio.py\", line 2502, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/anyio/_backends/_asyncio.py\", line 986, in run\n",
            "    result = context.run(func, *args)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/utils.py\", line 833, in run_sync_iterator_async\n",
            "    return next(iterator)\n",
            "           ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/utils.py\", line 1017, in gen_wrapper\n",
            "    response = next(iterator)\n",
            "               ^^^^^^^^^^^^^^\n",
            "  File \"/content/Ace-Step-v1.5/acestep/gradio_ui/events/__init__.py\", line 716, in generation_wrapper\n",
            "    raise gr.Error(f\"Failed to create sample: {result.status_message}\")\n",
            "gradio.exceptions.Error: 'Failed to create sample: ‚ùå Error generating from formatted prompt: FlashAttention only supports Ampere GPUs or newer.'\n"
          ]
        }
      ],
      "source": [
        "# @title 3. Download Models & Launch Interface\n",
        "# This cell first downloads the heavy model files (safetensors) and then starts the app.\n",
        "import os\n",
        "os.environ[\"USE_FLASH_ATTENTION\"] = \"0\"\n",
        "\n",
        "os.environ[\"VLLM_USE_FLASH_ATTN\"] = \"0\"                  # Upstream vLLM var\n",
        "os.environ[\"VLLM_ATTENTION_BACKEND\"] = \"TORCH_SDPA\"      # ‚Üê Key: force torch's built-in scaled_dot_product_attention (no flash)\n",
        "# Optional extra (some repos respect this):\n",
        "os.environ[\"FLASH_ATTENTION\"] = \"0\"\n",
        "if os.getcwd() != \"/content/Ace-Step-v1.5\":\n",
        "    os.chdir(\"/content/Ace-Step-v1.5\")\n",
        "\n",
        "# --- LITE MODE CONFIG ---\n",
        "os.environ[\"SERVICE_MODE_DIT_MODEL_2\"] = \"\" # Disable 2nd model download/load\n",
        "os.environ[\"SERVICE_MODE_BACKEND\"] = \"pt\"\n",
        "\n",
        "# 1. CREATE DOWNLOAD SCRIPT\n",
        "# Note: Double backslashes (\\\\n) are used to prevent Python from breaking strings across lines in the file\n",
        "download_code = \"\"\"\n",
        "import os\n",
        "os.environ[\"USE_FLASH_ATTENTION\"] = \"0\"\n",
        "os.environ[\"VLLM_USE_FLASH_ATTN\"] = \"0\"\n",
        "os.environ[\"FLASH_ATTENTION\"] = \"0\"\n",
        "os.environ[\"ATTN_BACKEND\"] = \"torch\"\n",
        "os.environ[\"TORCH_USE_CUDA_SDPA\"] = \"1\"\n",
        "import sys\n",
        "import torch\n",
        "\n",
        "print(\"Initializing download sequence...\")\n",
        "current_dir = os.getcwd()\n",
        "sys.path.insert(0, os.path.join(current_dir, \"acestep\", \"third_parts\", \"nano-vllm\"))\n",
        "\n",
        "from acestep.handler import AceStepHandler\n",
        "\n",
        "# Initialize handler to trigger download logic\n",
        "# We force CPU offload to avoid filling GPU RAM just for downloading\n",
        "handler = AceStepHandler(persistent_storage_path=os.path.join(current_dir, \"data\"))\n",
        "\n",
        "print(\"Downloading ACE-Step v1.5 Unified Repo (This includes DiT and LLM)...\")\n",
        "print(\"This may take a while (approx 10GB)...\")\n",
        "\n",
        "config_path = \"acestep-v15-turbo\"\n",
        "\n",
        "# Use internal method if available to force download, otherwise init\n",
        "try:\n",
        "    if hasattr(handler, '_ensure_model_downloaded'):\n",
        "        handler._ensure_model_downloaded(current_dir, config_path)\n",
        "        print(\"\\\\n‚úÖ Download complete.\")\n",
        "    else:\n",
        "        print(\"Standard initialization...\")\n",
        "        handler.initialize_service(current_dir, config_path, device='cpu', offload_to_cpu=True)\n",
        "except Exception as e:\n",
        "    print(f\"\\\\nDownload process finished (check for errors above if any): {e}\")\n",
        "\"\"\"\n",
        "\n",
        "with open(\"download_models.py\", \"w\") as f:\n",
        "    f.write(download_code)\n",
        "\n",
        "# 2. RUN DOWNLOAD\n",
        "print(\"‚è≥ Starting Model Download... (This prevents timeouts)\")\n",
        "!python download_models.py\n",
        "\n",
        "# 3. LAUNCH APP\n",
        "print(\"=\"*60)\n",
        "print(\"üöÄ Models ready. Launching ACE-Step Interface...\")\n",
        "print(\"üîó Click the public link ending in 'gradio.live' below once it appears.\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "!python app.py"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}